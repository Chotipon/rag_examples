{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üì¶ FAISS Index Creation\n",
    "\n",
    "This notebook demonstrates how to:\n",
    "1. Load sentences from a CSV file\n",
    "2. Generate embeddings using Sentence Transformers\n",
    "3. Create a FAISS index for efficient similarity search\n",
    "4. Save the index for later use\n",
    "\n",
    "## What is FAISS?\n",
    "\n",
    "**FAISS** (Facebook AI Similarity Search) is a library for efficient similarity search and clustering of dense vectors. It's widely used in production systems for:\n",
    "- Semantic search\n",
    "- Recommendation systems\n",
    "- Duplicate detection\n",
    "- RAG (Retrieval-Augmented Generation) systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install faiss-cpu sentence-transformers pandas numpy -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Load Sentences from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the sentences CSV file\n",
    "df = pd.read_csv('sentences.csv')\n",
    "\n",
    "print(f\"üìä Loaded {len(df)} sentences\")\n",
    "print(f\"\\nüìÅ Columns: {list(df.columns)}\")\n",
    "print(f\"\\nüìÇ Categories: {df['category'].unique().tolist()}\")\n",
    "print(f\"\\nüî¢ Sentences per category:\")\n",
    "print(df['category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview some sentences\n",
    "print(\"üìù Sample sentences:\\n\")\n",
    "for i, row in df.head(10).iterrows():\n",
    "    print(f\"  [{row['category']:12}] {row['text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Initialize Embedding Model\n",
    "\n",
    "We'll use the `all-MiniLM-L6-v2` model which is:\n",
    "- Fast and lightweight\n",
    "- Good quality embeddings\n",
    "- Perfect for demonstrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the embedding model\n",
    "print(\"üîÑ Loading embedding model...\")\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Get embedding dimension\n",
    "embedding_dim = model.get_sentence_embedding_dimension()\n",
    "print(f\"‚úÖ Model loaded!\")\n",
    "print(f\"üìê Embedding dimension: {embedding_dim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Generate Embeddings\n",
    "\n",
    "Convert all sentences to numerical vectors (embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sentences as a list\n",
    "sentences = df['text'].tolist()\n",
    "\n",
    "# Generate embeddings\n",
    "print(\"üîÑ Generating embeddings...\")\n",
    "start_time = time.time()\n",
    "\n",
    "embeddings = model.encode(\n",
    "    sentences,\n",
    "    show_progress_bar=True,\n",
    "    convert_to_numpy=True\n",
    ")\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"\\n‚úÖ Embeddings generated in {elapsed_time:.2f} seconds\")\n",
    "print(f\"üìê Embeddings shape: {embeddings.shape}\")\n",
    "print(f\"   - {embeddings.shape[0]} sentences\")\n",
    "print(f\"   - {embeddings.shape[1]} dimensions per embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize embeddings for cosine similarity\n",
    "# FAISS uses L2 distance by default, but normalized vectors + L2 = cosine similarity\n",
    "faiss.normalize_L2(embeddings)\n",
    "print(\"‚úÖ Embeddings normalized for cosine similarity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Create FAISS Index\n",
    "\n",
    "FAISS offers different index types:\n",
    "- `IndexFlatL2` - Exact search, good for small datasets\n",
    "- `IndexFlatIP` - Inner Product (for cosine similarity with normalized vectors)\n",
    "- `IndexIVFFlat` - Approximate search, faster for large datasets\n",
    "\n",
    "For our 100 sentences, we'll use `IndexFlatIP` for exact cosine similarity search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FAISS index\n",
    "print(\"üîÑ Creating FAISS index...\")\n",
    "\n",
    "# IndexFlatIP = Inner Product index (cosine similarity for normalized vectors)\n",
    "index = faiss.IndexFlatIP(embedding_dim)\n",
    "\n",
    "# Add embeddings to the index\n",
    "index.add(embeddings)\n",
    "\n",
    "print(f\"‚úÖ FAISS index created!\")\n",
    "print(f\"üìä Total vectors in index: {index.ntotal}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Quick Test - Verify the Index Works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test query\n",
    "test_query = \"What programming language should I learn?\"\n",
    "\n",
    "# Generate embedding for query\n",
    "query_embedding = model.encode([test_query], convert_to_numpy=True)\n",
    "faiss.normalize_L2(query_embedding)\n",
    "\n",
    "# Search for top 5 similar sentences\n",
    "k = 5\n",
    "distances, indices = index.search(query_embedding, k)\n",
    "\n",
    "print(f\"üîç Query: '{test_query}'\")\n",
    "print(f\"\\nüìã Top {k} most similar sentences:\\n\")\n",
    "\n",
    "for i, (dist, idx) in enumerate(zip(distances[0], indices[0])):\n",
    "    print(f\"  {i+1}. [Score: {dist:.4f}] [{df.iloc[idx]['category']:12}]\")\n",
    "    print(f\"     {df.iloc[idx]['text']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8Ô∏è‚É£ Save the Index and Metadata\n",
    "\n",
    "We need to save:\n",
    "1. The FAISS index file\n",
    "2. The sentences/metadata for retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save FAISS index\n",
    "faiss.write_index(index, 'sentences.faiss')\n",
    "print(\"‚úÖ FAISS index saved to 'sentences.faiss'\")\n",
    "\n",
    "# Save metadata (sentences and categories)\n",
    "metadata = {\n",
    "    'sentences': sentences,\n",
    "    'categories': df['category'].tolist(),\n",
    "    'ids': df['id'].tolist(),\n",
    "    'model_name': 'all-MiniLM-L6-v2',\n",
    "    'embedding_dim': embedding_dim\n",
    "}\n",
    "\n",
    "with open('sentences_metadata.pkl', 'wb') as f:\n",
    "    pickle.dump(metadata, f)\n",
    "\n",
    "print(\"‚úÖ Metadata saved to 'sentences_metadata.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify saved files\n",
    "import os\n",
    "\n",
    "files = ['sentences.faiss', 'sentences_metadata.pkl']\n",
    "print(\"üìÅ Saved files:\\n\")\n",
    "for file in files:\n",
    "    if os.path.exists(file):\n",
    "        size = os.path.getsize(file) / 1024  # KB\n",
    "        print(f\"  ‚úÖ {file} ({size:.2f} KB)\")\n",
    "    else:\n",
    "        print(f\"  ‚ùå {file} not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Summary\n",
    "\n",
    "In this notebook, we:\n",
    "1. ‚úÖ Loaded 100 sentences from CSV\n",
    "2. ‚úÖ Generated embeddings using Sentence Transformers\n",
    "3. ‚úÖ Created a FAISS index for similarity search\n",
    "4. ‚úÖ Tested the index with a sample query\n",
    "5. ‚úÖ Saved the index and metadata for later use\n",
    "\n",
    "**Next Step:** Use `05_faiss_vector_search.ipynb` to explore different search queries and understand how vector search works!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üß© Bonus: Understanding Index Types\n",
    "\n",
    "| Index Type | Description | Best For |\n",
    "|------------|-------------|----------|\n",
    "| `IndexFlatL2` | Exact L2 distance | Small datasets (<10K) |\n",
    "| `IndexFlatIP` | Exact Inner Product | Cosine similarity (normalized) |\n",
    "| `IndexIVFFlat` | Approximate search | Medium datasets (10K-1M) |\n",
    "| `IndexHNSW` | Graph-based search | Large datasets, high recall |\n",
    "| `IndexIVFPQ` | Compressed vectors | Very large datasets |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
