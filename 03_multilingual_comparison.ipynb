{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üåç Part 3: Multilingual Model Comparison\n",
    "\n",
    "Not all embedding models support all languages! In this notebook, we'll explore what happens when you use:\n",
    "- An **English-only model** with Thai text\n",
    "- A **multilingual model** with Thai text\n",
    "\n",
    "## What You'll Learn:\n",
    "1. Why language support matters for embeddings\n",
    "2. What happens when you use an unsupported language\n",
    "3. How to choose the right model for multilingual RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (run this in Colab)\n",
    "!pip install sentence-transformers plotly seaborn scikit-learn -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìù Define Bilingual Word List (English + Thai)\n",
    "\n",
    "We'll use the **same words** in both English and Thai to see how models handle them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# üîß BILINGUAL WORD LIST (English + Thai)\n",
    "# ============================================================\n",
    "\n",
    "bilingual_words = {\n",
    "    # Fruits\n",
    "    \"üçé Fruits (EN)\": [\"apple\", \"banana\", \"orange\", \"mango\", \"grape\"],\n",
    "    \"üçé ‡∏ú‡∏•‡πÑ‡∏°‡πâ (TH)\": [\"‡πÅ‡∏≠‡∏õ‡πÄ‡∏õ‡∏¥‡πâ‡∏•\", \"‡∏Å‡∏•‡πâ‡∏ß‡∏¢\", \"‡∏™‡πâ‡∏°\", \"‡∏°‡∏∞‡∏°‡πà‡∏ß‡∏á\", \"‡∏≠‡∏á‡∏∏‡πà‡∏ô\"],\n",
    "    \n",
    "    # Animals\n",
    "    \"üêæ Animals (EN)\": [\"dog\", \"cat\", \"elephant\", \"bird\", \"fish\"],\n",
    "    \"üêæ ‡∏™‡∏±‡∏ï‡∏ß‡πå (TH)\": [\"‡∏™‡∏∏‡∏ô‡∏±‡∏Ç\", \"‡πÅ‡∏°‡∏ß\", \"‡∏ä‡πâ‡∏≤‡∏á\", \"‡∏ô‡∏Å\", \"‡∏õ‡∏•‡∏≤\"],\n",
    "    \n",
    "    # Colors\n",
    "    \"üé® Colors (EN)\": [\"red\", \"blue\", \"green\", \"yellow\", \"white\"],\n",
    "    \"üé® ‡∏™‡∏µ (TH)\": [\"‡∏™‡∏µ‡πÅ‡∏î‡∏á\", \"‡∏™‡∏µ‡∏ô‡πâ‡∏≥‡πÄ‡∏á‡∏¥‡∏ô\", \"‡∏™‡∏µ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß\", \"‡∏™‡∏µ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏á\", \"‡∏™‡∏µ‡∏Ç‡∏≤‡∏ß\"],\n",
    "    \n",
    "    # Food\n",
    "    \"üçú Food (EN)\": [\"rice\", \"noodle\", \"chicken\", \"soup\", \"salad\"],\n",
    "    \"üçú ‡∏≠‡∏≤‡∏´‡∏≤‡∏£ (TH)\": [\"‡∏Ç‡πâ‡∏≤‡∏ß\", \"‡∏Å‡πã‡∏ß‡∏¢‡πÄ‡∏ï‡∏µ‡πã‡∏¢‡∏ß\", \"‡πÑ‡∏Å‡πà\", \"‡∏ã‡∏∏‡∏õ\", \"‡∏™‡∏•‡∏±‡∏î\"]\n",
    "}\n",
    "\n",
    "# Flatten\n",
    "words = []\n",
    "categories = []\n",
    "languages = []\n",
    "\n",
    "for category, word_list in bilingual_words.items():\n",
    "    words.extend(word_list)\n",
    "    categories.extend([category] * len(word_list))\n",
    "    lang = \"Thai\" if \"(TH)\" in category else \"English\"\n",
    "    languages.extend([lang] * len(word_list))\n",
    "\n",
    "print(f\"üìä Total words: {len(words)}\")\n",
    "print(f\"üá¨üáß English words: {languages.count('English')}\")\n",
    "print(f\"üáπüá≠ Thai words: {languages.count('Thai')}\")\n",
    "print(f\"\\nüìù Sample words:\")\n",
    "for cat, word_list in list(bilingual_words.items())[:4]:\n",
    "    print(f\"   {cat}: {word_list[:3]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ü§ñ Define Models to Compare\n",
    "\n",
    "We'll compare:\n",
    "1. **English-only model** - Does NOT support Thai\n",
    "2. **Multilingual model** - Supports 50+ languages including Thai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# üîß MODELS TO COMPARE\n",
    "# ============================================================\n",
    "\n",
    "models_config = {\n",
    "    \"all-MiniLM-L6-v2\": {\n",
    "        \"description\": \"English-only model (22M params)\",\n",
    "        \"supports_thai\": False,\n",
    "        \"languages\": \"English only\",\n",
    "        \"icon\": \"üá¨üáß\"\n",
    "    },\n",
    "    \"paraphrase-multilingual-MiniLM-L12-v2\": {\n",
    "        \"description\": \"Multilingual model (118M params, 50+ languages)\",\n",
    "        \"supports_thai\": True,\n",
    "        \"languages\": \"50+ languages including Thai\",\n",
    "        \"icon\": \"üåç\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"üìã Models to compare:\")\n",
    "print(\"=\" * 70)\n",
    "for name, config in models_config.items():\n",
    "    icon = config['icon']\n",
    "    thai_support = \"‚úÖ Yes\" if config['supports_thai'] else \"‚ùå No\"\n",
    "    print(f\"\\n{icon} {name}\")\n",
    "    print(f\"   {config['description']}\")\n",
    "    print(f\"   Thai Support: {thai_support}\")\n",
    "    print(f\"   Languages: {config['languages']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÑ Load Models & Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store results\n",
    "model_embeddings = {}\n",
    "loaded_models = {}\n",
    "\n",
    "for model_name in models_config.keys():\n",
    "    config = models_config[model_name]\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{config['icon']} Loading: {model_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    model = SentenceTransformer(model_name)\n",
    "    loaded_models[model_name] = model\n",
    "    \n",
    "    print(f\"   Embedding dimension: {model.get_sentence_embedding_dimension()}\")\n",
    "    print(f\"   Generating embeddings...\")\n",
    "    \n",
    "    embeddings = model.encode(words, show_progress_bar=True)\n",
    "    model_embeddings[model_name] = embeddings\n",
    "    \n",
    "    print(f\"   ‚úÖ Done! Shape: {embeddings.shape}\")\n",
    "\n",
    "print(f\"\\n\\nüéâ All models loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üåê 3D Visualization: English vs Thai Clustering\n",
    "\n",
    "**Key Question:** Do English and Thai translations of the same concept cluster together?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply t-SNE to each model\n",
    "tsne_results = {}\n",
    "perplexity = min(30, len(words) - 1)\n",
    "\n",
    "for model_name, embeddings in model_embeddings.items():\n",
    "    print(f\"üîÑ Applying t-SNE for {model_name}...\")\n",
    "    \n",
    "    tsne = TSNE(\n",
    "        n_components=3,\n",
    "        perplexity=perplexity,\n",
    "        random_state=42,\n",
    "        n_iter=1000,\n",
    "        learning_rate='auto',\n",
    "        init='pca'\n",
    "    )\n",
    "    \n",
    "    embeddings_3d = tsne.fit_transform(embeddings)\n",
    "    tsne_results[model_name] = embeddings_3d\n",
    "    print(f\"   ‚úÖ Done!\")\n",
    "\n",
    "print(\"\\nüéâ All t-SNE transformations complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 3D plots for each model - colored by LANGUAGE\n",
    "for model_name, embeddings_3d in tsne_results.items():\n",
    "    config = models_config[model_name]\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'word': words,\n",
    "        'category': categories,\n",
    "        'language': languages,\n",
    "        'x': embeddings_3d[:, 0],\n",
    "        'y': embeddings_3d[:, 1],\n",
    "        'z': embeddings_3d[:, 2]\n",
    "    })\n",
    "    \n",
    "    thai_support = \"‚úÖ Supports Thai\" if config['supports_thai'] else \"‚ùå Does NOT support Thai\"\n",
    "    \n",
    "    fig = px.scatter_3d(\n",
    "        df,\n",
    "        x='x', y='y', z='z',\n",
    "        color='language',\n",
    "        symbol='language',\n",
    "        text='word',\n",
    "        title=f\"{config['icon']} {model_name}<br><sub>{thai_support}</sub>\",\n",
    "        labels={'x': 't-SNE 1', 'y': 't-SNE 2', 'z': 't-SNE 3'},\n",
    "        height=600,\n",
    "        color_discrete_map={'English': '#3498db', 'Thai': '#e74c3c'}\n",
    "    )\n",
    "    \n",
    "    fig.update_traces(\n",
    "        marker=dict(size=10, line=dict(width=1, color='white')),\n",
    "        textposition='top center',\n",
    "        textfont=dict(size=9)\n",
    "    )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        legend=dict(\n",
    "            orientation=\"h\",\n",
    "            yanchor=\"bottom\",\n",
    "            y=-0.15,\n",
    "            xanchor=\"center\",\n",
    "            x=0.5\n",
    "        ),\n",
    "        margin=dict(l=0, r=0, b=100, t=80)\n",
    "    )\n",
    "    \n",
    "    fig.show()\n",
    "    print(f\"\\n{'‚îÄ'*60}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîç What Do You Notice?\n",
    "\n",
    "**English-only model (all-MiniLM-L6-v2):**\n",
    "- Thai words are likely clustered randomly or separately\n",
    "- No semantic understanding of Thai text\n",
    "- \"‡πÅ‡∏≠‡∏õ‡πÄ‡∏õ‡∏¥‡πâ‡∏•\" (apple) won't be near \"apple\"\n",
    "\n",
    "**Multilingual model (paraphrase-multilingual-MiniLM-L12-v2):**\n",
    "- Thai and English translations should cluster together!\n",
    "- \"‡πÅ‡∏≠‡∏õ‡πÄ‡∏õ‡∏¥‡πâ‡∏•\" (apple) should be near \"apple\"\n",
    "- Cross-lingual semantic understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üéØ Cross-Language Similarity Test\n",
    "\n",
    "The key test: Do translations have high similarity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define translation pairs to test\n",
    "translation_pairs = [\n",
    "    (\"apple\", \"‡πÅ‡∏≠‡∏õ‡πÄ‡∏õ‡∏¥‡πâ‡∏•\"),\n",
    "    (\"banana\", \"‡∏Å‡∏•‡πâ‡∏ß‡∏¢\"),\n",
    "    (\"dog\", \"‡∏™‡∏∏‡∏ô‡∏±‡∏Ç\"),\n",
    "    (\"cat\", \"‡πÅ‡∏°‡∏ß\"),\n",
    "    (\"elephant\", \"‡∏ä‡πâ‡∏≤‡∏á\"),\n",
    "    (\"red\", \"‡∏™‡∏µ‡πÅ‡∏î‡∏á\"),\n",
    "    (\"blue\", \"‡∏™‡∏µ‡∏ô‡πâ‡∏≥‡πÄ‡∏á‡∏¥‡∏ô\"),\n",
    "    (\"rice\", \"‡∏Ç‡πâ‡∏≤‡∏ß\"),\n",
    "    (\"chicken\", \"‡πÑ‡∏Å‡πà\"),\n",
    "]\n",
    "\n",
    "print(\"üéØ CROSS-LANGUAGE SIMILARITY TEST\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nDo English-Thai translation pairs have high similarity?\\n\")\n",
    "\n",
    "# Calculate similarity for each model\n",
    "similarity_matrices = {}\n",
    "for model_name, embeddings in model_embeddings.items():\n",
    "    similarity_matrices[model_name] = cosine_similarity(embeddings)\n",
    "\n",
    "# Header\n",
    "print(f\"{'English':<12} {'Thai':<12}\", end=\"\")\n",
    "for model_name in models_config.keys():\n",
    "    short_name = model_name.split('-')[0][:8]\n",
    "    print(f\"{short_name:^20}\", end=\"\")\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "\n",
    "# Compare each pair\n",
    "model_avg_scores = {name: [] for name in models_config.keys()}\n",
    "\n",
    "for en_word, th_word in translation_pairs:\n",
    "    if en_word in words and th_word in words:\n",
    "        idx_en = words.index(en_word)\n",
    "        idx_th = words.index(th_word)\n",
    "        \n",
    "        print(f\"{en_word:<12} {th_word:<12}\", end=\"\")\n",
    "        \n",
    "        for model_name in models_config.keys():\n",
    "            sim = similarity_matrices[model_name][idx_en, idx_th]\n",
    "            model_avg_scores[model_name].append(sim)\n",
    "            \n",
    "            # Color code\n",
    "            if sim > 0.7:\n",
    "                indicator = \"üü¢\"\n",
    "            elif sim > 0.4:\n",
    "                indicator = \"üü°\"\n",
    "            else:\n",
    "                indicator = \"üî¥\"\n",
    "            \n",
    "            print(f\"{indicator} {sim:.3f}            \", end=\"\")\n",
    "        print()\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä AVERAGE CROSS-LANGUAGE SIMILARITY:\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "for model_name in models_config.keys():\n",
    "    config = models_config[model_name]\n",
    "    avg = np.mean(model_avg_scores[model_name])\n",
    "    \n",
    "    if avg > 0.6:\n",
    "        grade = \"‚úÖ EXCELLENT - Model understands both languages!\"\n",
    "    elif avg > 0.3:\n",
    "        grade = \"üü° PARTIAL - Some cross-language understanding\"\n",
    "    else:\n",
    "        grade = \"‚ùå POOR - Model doesn't understand Thai properly\"\n",
    "    \n",
    "    print(f\"\\n{config['icon']} {model_name}\")\n",
    "    print(f\"   Average: {avg:.3f}\")\n",
    "    print(f\"   Result: {grade}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üî• Side-by-Side Heatmaps\n",
    "\n",
    "Let's compare the full similarity matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create heatmaps for each model\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "for ax, (model_name, sim_matrix) in zip(axes, similarity_matrices.items()):\n",
    "    config = models_config[model_name]\n",
    "    \n",
    "    sns.heatmap(\n",
    "        sim_matrix,\n",
    "        xticklabels=words,\n",
    "        yticklabels=words,\n",
    "        cmap='RdYlBu_r',\n",
    "        vmin=0,\n",
    "        vmax=1,\n",
    "        ax=ax,\n",
    "        cbar_kws={'shrink': 0.8}\n",
    "    )\n",
    "    \n",
    "    thai_support = \"‚úÖ Thai\" if config['supports_thai'] else \"‚ùå No Thai\"\n",
    "    ax.set_title(f\"{config['icon']} {model_name}\\n{thai_support}\", fontsize=11)\n",
    "    ax.tick_params(axis='x', rotation=90, labelsize=7)\n",
    "    ax.tick_params(axis='y', rotation=0, labelsize=7)\n",
    "\n",
    "plt.suptitle('Similarity Comparison: English-Only vs Multilingual Model', \n",
    "             fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîç Reading the Heatmaps\n",
    "\n",
    "Look at the **cross-language blocks** (where English words meet Thai words):\n",
    "\n",
    "**English-only model:**\n",
    "- Low similarity (blue) between English and Thai translations\n",
    "- Thai words might have random similarities\n",
    "\n",
    "**Multilingual model:**\n",
    "- High similarity (red) between translations\n",
    "- \"apple\" and \"‡πÅ‡∏≠‡∏õ‡πÄ‡∏õ‡∏¥‡πâ‡∏•\" should show bright red"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üß™ What Happens with Unsupported Languages?\n",
    "\n",
    "Let's investigate what the English-only model \"sees\" when given Thai text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üî¨ INVESTIGATING: What does an English-only model see in Thai?\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Get the English-only model\n",
    "english_model = loaded_models[\"all-MiniLM-L6-v2\"]\n",
    "english_sim = similarity_matrices[\"all-MiniLM-L6-v2\"]\n",
    "\n",
    "# Find what Thai words are most similar to\n",
    "thai_words_idx = [i for i, lang in enumerate(languages) if lang == \"Thai\"]\n",
    "\n",
    "print(\"\\nFor each Thai word, what is it most similar to?\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for thai_idx in thai_words_idx[:8]:  # Show first 8\n",
    "    thai_word = words[thai_idx]\n",
    "    \n",
    "    # Get similarities to all other words\n",
    "    similarities = english_sim[thai_idx].copy()\n",
    "    similarities[thai_idx] = -1  # Exclude self\n",
    "    \n",
    "    # Find top 3 most similar\n",
    "    top_indices = np.argsort(similarities)[-3:][::-1]\n",
    "    \n",
    "    print(f\"\\nüáπüá≠ {thai_word}\")\n",
    "    print(f\"   Most similar to:\")\n",
    "    for idx in top_indices:\n",
    "        sim = similarities[idx]\n",
    "        similar_word = words[idx]\n",
    "        lang_icon = \"üá¨üáß\" if languages[idx] == \"English\" else \"üáπüá≠\"\n",
    "        print(f\"      {lang_icon} {similar_word}: {sim:.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\\nüí° INSIGHT: English-only models often cluster Thai words based on\")\n",
    "print(\"   character patterns, not meaning. Thai words may cluster with\")\n",
    "print(\"   other Thai words or random English words!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìä Summary: Model Language Support Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary visualization\n",
    "summary_data = []\n",
    "\n",
    "for model_name in models_config.keys():\n",
    "    config = models_config[model_name]\n",
    "    avg_cross_lang = np.mean(model_avg_scores[model_name])\n",
    "    \n",
    "    summary_data.append({\n",
    "        'Model': model_name,\n",
    "        'Thai Support': 'Yes' if config['supports_thai'] else 'No',\n",
    "        'Cross-Language Similarity': avg_cross_lang\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "# Bar chart\n",
    "fig = px.bar(\n",
    "    summary_df,\n",
    "    x='Model',\n",
    "    y='Cross-Language Similarity',\n",
    "    color='Thai Support',\n",
    "    title='üìä Cross-Language Understanding: English‚ÜîThai Translation Similarity',\n",
    "    color_discrete_map={'Yes': '#2ecc71', 'No': '#e74c3c'},\n",
    "    height=400\n",
    ")\n",
    "\n",
    "fig.add_hline(y=0.7, line_dash=\"dash\", line_color=\"green\", \n",
    "              annotation_text=\"Good threshold (0.7)\")\n",
    "fig.add_hline(y=0.4, line_dash=\"dash\", line_color=\"orange\",\n",
    "              annotation_text=\"Poor threshold (0.4)\")\n",
    "\n",
    "fig.update_layout(yaxis_range=[0, 1])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üéì Key Takeaways\n",
    "\n",
    "### ‚ùå What happens with UNSUPPORTED languages:\n",
    "- Words are tokenized without understanding\n",
    "- Similar meanings DON'T get similar embeddings\n",
    "- \"apple\" and \"‡πÅ‡∏≠‡∏õ‡πÄ‡∏õ‡∏¥‡πâ‡∏•\" are treated as unrelated\n",
    "- RAG retrieval will FAIL for non-English queries!\n",
    "\n",
    "### ‚úÖ What happens with SUPPORTED languages:\n",
    "- Cross-language semantic understanding\n",
    "- Translations have HIGH similarity scores\n",
    "- RAG can match Thai queries to English documents (and vice versa)\n",
    "\n",
    "### üéØ For Thai RAG Applications:\n",
    "| Use Case | Recommended Model |\n",
    "|----------|------------------|\n",
    "| Thai-only content | `paraphrase-multilingual-MiniLM-L12-v2` |\n",
    "| Thai + English mixed | `paraphrase-multilingual-MiniLM-L12-v2` |\n",
    "| English-only content | `all-MiniLM-L6-v2` (faster) |\n",
    "| High quality multilingual | `paraphrase-multilingual-mpnet-base-v2` |\n",
    "\n",
    "### üìö More Multilingual Models to Try:\n",
    "- `distiluse-base-multilingual-cased-v2` (15 languages)\n",
    "- `paraphrase-multilingual-mpnet-base-v2` (50+ languages, higher quality)\n",
    "- `LaBSE` (109 languages, by Google)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üß™ Try Your Own Languages!\n",
    "\n",
    "Modify the code below to test other languages you work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîß TEST YOUR OWN TRANSLATIONS\n",
    "# Add your own language pairs here!\n",
    "\n",
    "custom_translations = [\n",
    "    (\"hello\", \"‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ\"),      # Thai\n",
    "    (\"thank you\", \"‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì\"),  # Thai\n",
    "    (\"good morning\", \"‡∏≠‡∏£‡∏∏‡∏ì‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏¥‡πå\"),  # Thai\n",
    "    # Add more pairs here!\n",
    "]\n",
    "\n",
    "print(\"üß™ Testing custom translation pairs:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "multilingual_model = loaded_models[\"paraphrase-multilingual-MiniLM-L12-v2\"]\n",
    "english_model = loaded_models[\"all-MiniLM-L6-v2\"]\n",
    "\n",
    "for en, th in custom_translations:\n",
    "    # Get embeddings\n",
    "    en_emb_multi = multilingual_model.encode([en])\n",
    "    th_emb_multi = multilingual_model.encode([th])\n",
    "    \n",
    "    en_emb_eng = english_model.encode([en])\n",
    "    th_emb_eng = english_model.encode([th])\n",
    "    \n",
    "    # Calculate similarity\n",
    "    sim_multi = cosine_similarity(en_emb_multi, th_emb_multi)[0][0]\n",
    "    sim_eng = cosine_similarity(en_emb_eng, th_emb_eng)[0][0]\n",
    "    \n",
    "    print(f\"\\n'{en}' ‚Üî '{th}'\")\n",
    "    print(f\"   üåç Multilingual model: {sim_multi:.3f}\")\n",
    "    print(f\"   üá¨üáß English-only model: {sim_eng:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
