# ğŸ“š RAG Workshop: Understanding Retrieval-Augmented Generation

Welcome to this hands-on workshop on **Retrieval-Augmented Generation (RAG)**!

## ğŸ¤” What is RAG?

**RAG** combines the power of:
1. **Retrieval** - Finding relevant information from a knowledge base
2. **Augmentation** - Adding that information to your prompt
3. **Generation** - Using an LLM to generate responses with context

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        RAG Pipeline                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚   User Query                                                     â”‚
â”‚       â”‚                                                          â”‚
â”‚       â–¼                                                          â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚   â”‚ Embed Query     â”‚â”€â”€â”€â–¶â”‚ Search Vector Database          â”‚    â”‚
â”‚   â”‚ (Text â†’ Vector) â”‚    â”‚ (Find Similar Embeddings)       â”‚    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                        â”‚                         â”‚
â”‚                                        â–¼                         â”‚
â”‚                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚                          â”‚ Retrieved Documents             â”‚    â”‚
â”‚                          â”‚ (Top-K Most Relevant)           â”‚    â”‚
â”‚                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                        â”‚                         â”‚
â”‚                                        â–¼                         â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚ Augmented Prompt = Query + Retrieved Context            â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                     â”‚                            â”‚
â”‚                                     â–¼                            â”‚
â”‚                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚                          â”‚ LLM Generates Response          â”‚    â”‚
â”‚                          â”‚ (With Knowledge Context)        â”‚    â”‚
â”‚                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ¯ Workshop Objectives

By the end of this workshop, you will understand:
- How words/sentences are converted to **embeddings** (vectors)
- How **similarity** is measured between embeddings
- Why different **embedding models** produce different results
- The foundation for building RAG systems

## ğŸ““ Workshop Notebooks

| Notebook | Description |
|----------|-------------|
| `01_embedding_visualization.ipynb` | Visualize word embeddings in 3D space + Cosine similarity heatmap |
| `02_model_comparison.ipynb` | Compare how different embedding models represent the same words |
| `03_multilingual_comparison.ipynb` | **NEW!** Compare Thai support: what happens with unsupported languages? |

## ğŸš€ Getting Started

### Option 1: Google Colab (Recommended)
1. Upload notebooks to Google Colab
2. Run each cell from top to bottom
3. Dependencies are installed automatically

### Option 2: Local Environment
```bash
pip install -r requirements.txt
jupyter notebook
```

## ğŸ“¦ Dependencies

- `sentence-transformers` - Pre-trained embedding models
- `plotly` - Interactive 3D visualizations
- `seaborn` - Beautiful heatmaps
- `scikit-learn` - t-SNE dimensionality reduction
- `numpy`, `pandas` - Data manipulation

## ğŸ”‘ Key Concepts

### Embeddings
Embeddings convert text (words, sentences, documents) into numerical vectors. Similar meanings = similar vectors!

### Cosine Similarity
Measures the angle between two vectors. Range: -1 to 1
- **1.0** = Identical direction (most similar)
- **0.0** = Perpendicular (unrelated)
- **-1.0** = Opposite direction (most dissimilar)

### t-SNE
A technique to visualize high-dimensional data (768+ dimensions) in 2D or 3D while preserving relative distances.

---

Happy Learning! ğŸ‰
