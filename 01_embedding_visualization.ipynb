{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéØ Part 1: Word Embedding Visualization\n",
    "\n",
    "In this notebook, we'll explore how words are represented as vectors (embeddings) and visualize their relationships.\n",
    "\n",
    "## What You'll Learn:\n",
    "1. How to convert words to embeddings using pre-trained models\n",
    "2. Visualize word relationships in 3D space using t-SNE\n",
    "3. Measure similarity between words using cosine similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install required packages (run this in Colab)\n",
    "!pip install sentence-transformers plotly seaborn scikit-learn -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SK_bi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing _C: The specified module could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmanifold\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TSNE\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpairwise\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cosine_similarity\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SK_bi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sentence_transformers\\__init__.py:10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     11\u001b[39m     export_dynamic_quantized_onnx_model,\n\u001b[32m     12\u001b[39m     export_optimized_onnx_model,\n\u001b[32m     13\u001b[39m     export_static_quantized_openvino_model,\n\u001b[32m     14\u001b[39m )\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcross_encoder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     16\u001b[39m     CrossEncoder,\n\u001b[32m     17\u001b[39m     CrossEncoderModelCardData,\n\u001b[32m     18\u001b[39m     CrossEncoderTrainer,\n\u001b[32m     19\u001b[39m     CrossEncoderTrainingArguments,\n\u001b[32m     20\u001b[39m )\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ParallelSentencesDataset, SentencesDataset\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SK_bi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sentence_transformers\\backend\\__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m__future__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mload\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_onnx_model, load_openvino_model\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01moptimize\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m export_optimized_onnx_model\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mquantize\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m export_dynamic_quantized_onnx_model, export_static_quantized_openvino_model\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SK_bi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sentence_transformers\\backend\\load.py:7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlogging\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfiguration_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PretrainedConfig\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _save_pretrained_wrapper, backend_should_export, backend_warn_to_save\n\u001b[32m     11\u001b[39m logger = logging.getLogger(\u001b[34m__name__\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SK_bi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\__init__.py:27\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Check the dependencies satisfy the minimal versions required.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dependency_versions_check\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     29\u001b[39m     OptionalDependencyNotAvailable,\n\u001b[32m     30\u001b[39m     _LazyModule,\n\u001b[32m   (...)\u001b[39m\u001b[32m     49\u001b[39m     logging,\n\u001b[32m     50\u001b[39m )\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimport_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m define_import_structure\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SK_bi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\dependency_versions_check.py:16\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright 2020 The HuggingFace Team. All rights reserved.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdependency_versions_table\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m deps\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mversions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m require_version, require_version_core\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# define which module versions we always want to check at run time\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# (usually the ones defined in `install_requires` in setup.py)\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# order specific notes:\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# - tqdm must be checked before tokenizers\u001b[39;00m\n\u001b[32m     25\u001b[39m pkgs_to_check_at_runtime = [\n\u001b[32m     26\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     27\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtqdm\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     37\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mpyyaml\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     38\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SK_bi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\__init__.py:25\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackbone_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BackboneConfigMixin, BackboneMixin\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchat_template_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DocstringParsingException, TypeHintParsingException, get_json_schema\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconstants\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD, IMAGENET_STANDARD_MEAN, IMAGENET_STANDARD_STD\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdoc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     28\u001b[39m     add_code_sample_docstrings,\n\u001b[32m     29\u001b[39m     add_end_docstrings,\n\u001b[32m   (...)\u001b[39m\u001b[32m     33\u001b[39m     replace_return_docstrings,\n\u001b[32m     34\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SK_bi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\chat_template_utils.py:40\u001b[39m\n\u001b[32m     37\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mPIL\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mImage\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_torch_available():\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Tensor\n\u001b[32m     43\u001b[39m BASIC_TYPES = (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbool\u001b[39m, Any, \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m), ...)\n\u001b[32m     44\u001b[39m \u001b[38;5;66;03m# Extracts the initial segment of the docstring, containing the function description\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\SK_bi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\__init__.py:409\u001b[39m\n\u001b[32m    407\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m USE_GLOBAL_DEPS:\n\u001b[32m    408\u001b[39m         _load_global_deps()\n\u001b[32m--> \u001b[39m\u001b[32m409\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_C\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *  \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[32m    412\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mSymInt\u001b[39;00m:\n\u001b[32m    413\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    414\u001b[39m \u001b[33;03m    Like an int (including magic methods), but redirects all operations on the\u001b[39;00m\n\u001b[32m    415\u001b[39m \u001b[33;03m    wrapped node. This is used in particular to symbolically record operations\u001b[39;00m\n\u001b[32m    416\u001b[39m \u001b[33;03m    in the symbolic shape workflow.\u001b[39;00m\n\u001b[32m    417\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: DLL load failed while importing _C: The specified module could not be found."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üé® PART 1: 3D Visualization of Word Embeddings\n",
    "\n",
    "We'll define categories of words and see how they cluster together in embedding space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìù Define Your Word List\n",
    "\n",
    "Modify the dictionary below to explore different word relationships!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# üîß CUSTOMIZE YOUR WORD LIST HERE!\n",
    "# ============================================================\n",
    "# Group words by category - words in the same category should cluster together\n",
    "\n",
    "word_categories = {\n",
    "    \"üçé Fruits\": [\n",
    "        \"apple\", \"banana\", \"orange\", \"mango\", \"strawberry\", \"grape\"\n",
    "    ],\n",
    "    \"üêæ Animals\": [\n",
    "        \"dog\", \"cat\", \"elephant\", \"lion\", \"tiger\", \"rabbit\"\n",
    "    ],\n",
    "    \"üé® Colors\": [\n",
    "        \"red\", \"blue\", \"green\", \"yellow\", \"purple\", \"orange\"\n",
    "    ],\n",
    "    \"üíª Technology\": [\n",
    "        \"computer\", \"smartphone\", \"laptop\", \"tablet\", \"keyboard\", \"mouse\"\n",
    "    ],\n",
    "    \"üöó Vehicles\": [\n",
    "        \"car\", \"bicycle\", \"motorcycle\", \"airplane\", \"train\", \"boat\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Flatten the dictionary into lists\n",
    "words = []\n",
    "categories = []\n",
    "for category, word_list in word_categories.items():\n",
    "    words.extend(word_list)\n",
    "    categories.extend([category] * len(word_list))\n",
    "\n",
    "print(f\"üìä Total words: {len(words)}\")\n",
    "print(f\"üìÅ Categories: {list(word_categories.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ Load Embedding Model & Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained sentence transformer model\n",
    "# This model converts text into 384-dimensional vectors\n",
    "model_name = \"all-MiniLM-L6-v2\"\n",
    "print(f\"üîÑ Loading model: {model_name}...\")\n",
    "\n",
    "model = SentenceTransformer(model_name)\n",
    "print(f\"‚úÖ Model loaded! Embedding dimension: {model.get_sentence_embedding_dimension()}\")\n",
    "\n",
    "# Generate embeddings for all words\n",
    "print(\"\\nüîÑ Generating embeddings...\")\n",
    "embeddings = model.encode(words, show_progress_bar=True)\n",
    "\n",
    "print(f\"\\n‚úÖ Embeddings shape: {embeddings.shape}\")\n",
    "print(f\"   - {embeddings.shape[0]} words\")\n",
    "print(f\"   - {embeddings.shape[1]} dimensions per word\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìâ Reduce Dimensions with t-SNE\n",
    "\n",
    "We have 384-dimensional vectors, but we can only visualize in 3D. t-SNE helps us reduce dimensions while preserving relative distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply t-SNE to reduce to 3 dimensions\n",
    "print(\"üîÑ Applying t-SNE (this may take a moment)...\")\n",
    "\n",
    "# Adjust perplexity based on number of samples\n",
    "perplexity = min(30, len(words) - 1)\n",
    "\n",
    "tsne = TSNE(\n",
    "    n_components=3,           # 3D output\n",
    "    perplexity=perplexity,    # Balance between local and global structure\n",
    "    random_state=42,          # For reproducibility\n",
    "    n_iter=1000,              # Number of iterations\n",
    "    learning_rate='auto',\n",
    "    init='pca'                # Initialize with PCA for better results\n",
    ")\n",
    "\n",
    "embeddings_3d = tsne.fit_transform(embeddings)\n",
    "print(f\"‚úÖ Reduced to shape: {embeddings_3d.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üåê Interactive 3D Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for Plotly\n",
    "df = pd.DataFrame({\n",
    "    'word': words,\n",
    "    'category': categories,\n",
    "    'x': embeddings_3d[:, 0],\n",
    "    'y': embeddings_3d[:, 1],\n",
    "    'z': embeddings_3d[:, 2]\n",
    "})\n",
    "\n",
    "# Create interactive 3D scatter plot\n",
    "fig = px.scatter_3d(\n",
    "    df,\n",
    "    x='x', y='y', z='z',\n",
    "    color='category',\n",
    "    text='word',\n",
    "    title='üìä Word Embeddings in 3D Space (t-SNE)',\n",
    "    labels={'x': 't-SNE 1', 'y': 't-SNE 2', 'z': 't-SNE 3'},\n",
    "    height=700,\n",
    "    color_discrete_sequence=px.colors.qualitative.Set1\n",
    ")\n",
    "\n",
    "# Customize the plot\n",
    "fig.update_traces(\n",
    "    marker=dict(size=10, line=dict(width=1, color='white')),\n",
    "    textposition='top center',\n",
    "    textfont=dict(size=10)\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    legend=dict(\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"bottom\",\n",
    "        y=-0.15,\n",
    "        xanchor=\"center\",\n",
    "        x=0.5\n",
    "    ),\n",
    "    scene=dict(\n",
    "        xaxis_title='t-SNE Dimension 1',\n",
    "        yaxis_title='t-SNE Dimension 2',\n",
    "        zaxis_title='t-SNE Dimension 3'\n",
    "    ),\n",
    "    margin=dict(l=0, r=0, b=100, t=50)\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"\\nüí° TIP: Drag to rotate, scroll to zoom, double-click to reset view!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîç What Do You Notice?\n",
    "\n",
    "- Do words from the same category cluster together?\n",
    "- Are there any surprising relationships?\n",
    "- What happens with words like \"orange\" (both fruit and color)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üìä PART 2: Cosine Similarity Heatmap\n",
    "\n",
    "Now let's measure how similar each pair of words is using **cosine similarity**.\n",
    "\n",
    "Cosine similarity = cos(Œ∏) between two vectors\n",
    "- **1.0** = Same direction (most similar)\n",
    "- **0.0** = Perpendicular (unrelated)  \n",
    "- **-1.0** = Opposite direction (least similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cosine similarity matrix\n",
    "similarity_matrix = cosine_similarity(embeddings)\n",
    "\n",
    "print(f\"‚úÖ Similarity matrix shape: {similarity_matrix.shape}\")\n",
    "print(f\"   (Each cell shows similarity between word i and word j)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî• Interactive Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create heatmap with Plotly for interactivity\n",
    "fig = go.Figure(data=go.Heatmap(\n",
    "    z=similarity_matrix,\n",
    "    x=words,\n",
    "    y=words,\n",
    "    colorscale='RdYlBu_r',  # Red = high similarity, Blue = low\n",
    "    zmin=0,\n",
    "    zmax=1,\n",
    "    hovertemplate='%{x} ‚Üî %{y}<br>Similarity: %{z:.3f}<extra></extra>'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='üî• Cosine Similarity Heatmap',\n",
    "    xaxis_title='Words',\n",
    "    yaxis_title='Words',\n",
    "    height=800,\n",
    "    width=900,\n",
    "    xaxis={'tickangle': 45},\n",
    "    yaxis={'autorange': 'reversed'}  # Put first word at top\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"\\nüí° TIP: Hover over cells to see exact similarity values!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Alternative: Seaborn Static Heatmap (with annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a static heatmap with annotations (if you prefer)\n",
    "plt.figure(figsize=(16, 14))\n",
    "\n",
    "# Create heatmap\n",
    "sns.heatmap(\n",
    "    similarity_matrix,\n",
    "    xticklabels=words,\n",
    "    yticklabels=words,\n",
    "    cmap='RdYlBu_r',\n",
    "    vmin=0,\n",
    "    vmax=1,\n",
    "    annot=len(words) <= 15,  # Show values only if not too many words\n",
    "    fmt='.2f',\n",
    "    square=True,\n",
    "    cbar_kws={'label': 'Cosine Similarity'}\n",
    ")\n",
    "\n",
    "plt.title('Cosine Similarity Between Word Embeddings', fontsize=14, fontweight='bold')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèÜ Find Most & Least Similar Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find most and least similar pairs (excluding self-comparisons)\n",
    "n_words = len(words)\n",
    "pairs = []\n",
    "\n",
    "for i in range(n_words):\n",
    "    for j in range(i + 1, n_words):  # Only upper triangle\n",
    "        pairs.append({\n",
    "            'word1': words[i],\n",
    "            'word2': words[j],\n",
    "            'similarity': similarity_matrix[i, j],\n",
    "            'category1': categories[i],\n",
    "            'category2': categories[j]\n",
    "        })\n",
    "\n",
    "pairs_df = pd.DataFrame(pairs).sort_values('similarity', ascending=False)\n",
    "\n",
    "print(\"üèÜ TOP 10 MOST SIMILAR PAIRS:\")\n",
    "print(\"=\" * 60)\n",
    "for idx, row in pairs_df.head(10).iterrows():\n",
    "    same_cat = \"‚úÖ\" if row['category1'] == row['category2'] else \"‚ùå\"\n",
    "    print(f\"{same_cat} {row['word1']:15} ‚Üî {row['word2']:15} : {row['similarity']:.4f}\")\n",
    "\n",
    "print(\"\\n\\n‚ùÑÔ∏è TOP 10 LEAST SIMILAR PAIRS:\")\n",
    "print(\"=\" * 60)\n",
    "for idx, row in pairs_df.tail(10).iterrows():\n",
    "    same_cat = \"‚úÖ\" if row['category1'] == row['category2'] else \"‚ùå\"\n",
    "    print(f\"{same_cat} {row['word1']:15} ‚Üî {row['word2']:15} : {row['similarity']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üéì Key Takeaways\n",
    "\n",
    "1. **Embeddings capture meaning** - Similar words have similar vectors\n",
    "2. **Dimensionality reduction** helps us visualize high-dimensional data\n",
    "3. **Cosine similarity** is the standard metric for comparing embeddings\n",
    "4. **Words can belong to multiple categories** (e.g., \"orange\")\n",
    "\n",
    "## üöÄ Next Steps\n",
    "\n",
    "Try modifying the `word_categories` dictionary to explore:\n",
    "- Different semantic categories\n",
    "- Synonyms and antonyms\n",
    "- Domain-specific vocabulary\n",
    "\n",
    "Then move on to **Notebook 2** to compare different embedding models!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
